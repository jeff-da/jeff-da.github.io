<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>EMU: Edited Media Undestanding</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><strong>EMU:</strong> <br> A Corpus on Visual Misinformation</h1>
        <p>We present the task of <strong>Edited Media Understanding</strong>, requiring models to answer open-ended questions that capture the intent and implications of an image edit. EMU contains 48k rich question-answer pairs written in rich natural language on the intent, implications, and potential for misinformation in edited images.</p>
        <ul>
          <li><a href="https://docs.google.com/forms/d/e/1FAIpQLSfus-v0sxyM_bq6hcMH5Zdn93N2nBlHfn40zwYYyRK1p830iw/viewform?usp=sf_link">Download <strong>dataset</strong></a></li>
          <li><a href="">Read on <strong>arXiv</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>48k Grounded Explainations over 8k Edits</h1>

        <img src="./images/example.svg" alt="EMU example" width="500" height="600">

        <p>Multimodal disinformation, from deepfakes to simple edits that deceive, is an important societal problem. Yet at the same time, the vast majority of media edits are harmless -- such as a filtered vacation photo. The difference between this example, and harmful edits that spread disinformation, is one of intent. Recognizing and describing this intent is a major challenge for today's AI systems.
          
        <p>We present the task of Edited Media Understanding, requiring models to answer open-ended questions that capture the intent and implications of an image edit. We introduce a dataset for our task, EMU, with 48k question-answer pairs written in rich natural language. Our dataset serves as a testbed for the utility of artifical intelligence models in battling visual misinformation.</p>

        <h1>Paper</h1>

        <h1><a href="">> read on arxiv</a></h1>

        <embed src="./images/paper.pdf" alt="EMU paper" width="500" height="600"> <br> <br>

        <h1>Authors</h1>

        This work was done by a team of researchers from the Allen Institute for AI, University of Washington, Stanford University, and the University of Michigan. <br> <br>
        <ul>
          <li><a href="https://jeffda.com/">Jeff Da</a>, Allen Institute for AI</li>
          <li><a href="https://maxwellforbes.com/">Max Forbes</a>, Allen Institute for AI + University of Washington</li>
          <li><a href="https://rowanzellers.com/">Rowan Zellers</a>, Allen Institute for AI + University of Washington</li>
          <li><a href="https://www.linkedin.com/in/zhengant/">Anthony Zheng</a>, University of Michigan</li>
          <li><a href="https://scholar.google.com/citations?user=qlJuej0AAAAJ&hl=en">Jena Hwang</a>, Allen Institute for AI</li>
          <li><a href="https://atcbosselut.github.io/">Antoine Bosselut</a>, Allen Institute for AI + Stanford University</li>
          <li><a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>, Allen Institute for AI + University of Washington</li>
        </ul>
      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
